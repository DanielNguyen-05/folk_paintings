"""FastAPI backend for LLM Council (Outpainting)."""

from fastapi import FastAPI, HTTPException, Form, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uuid
import os
import shutil
import cloudinary
import cloudinary.uploader

from . import storage
from .OutpaintingCouncil import OutpaintingCouncil

# --- Cáº¥u hÃ¬nh thÆ° má»¥c lÆ°u áº£nh Local ---
LOCAL_IMG_DIR = "local_storage/images"
os.makedirs(LOCAL_IMG_DIR, exist_ok=True)

app = FastAPI(title="Outpainting Council API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

council = OutpaintingCouncil()

# --- Pydantic Models ---
class CreateConversationRequest(BaseModel):
    title: Optional[str] = "New Outpainting Task"

class ConversationMetadata(BaseModel):
    id: str
    created_at: str
    title: str
    message_count: int

class Conversation(BaseModel):
    id: str
    created_at: str
    title: str
    messages: List[Dict[str, Any]]

# --- Endpoints ---

@app.get("/")
async def root():
    return {"status": "ok", "service": "Outpainting Council API"}

@app.get("/api/conversations", response_model=List[ConversationMetadata])
async def list_conversations():
    return storage.list_conversations()

@app.post("/api/conversations", response_model=Conversation)
async def create_conversation(request: CreateConversationRequest):
    conversation_id = str(uuid.uuid4())
    conversation = storage.create_conversation(conversation_id)
    if request.title:
        storage.update_conversation_title(conversation_id, request.title)
    return conversation

@app.get("/api/conversations/{conversation_id}", response_model=Conversation)
async def get_conversation(conversation_id: str):
    conversation = storage.get_conversation(conversation_id)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")
    return conversation

@app.post("/api/conversations/{conversation_id}/message")
async def send_message_and_process(
    conversation_id: str,
    content: str = Form(...), # User Prompt
    image: UploadFile | None = File(None)
):
    """
    Main Endpoint xá»­ lÃ½:
    1. Kiá»ƒm tra keyword ("scale", "expand", "outpainting"...).
    2. Náº¿u cÃ³ keyword + áº£nh -> LÆ°u Local -> Upload Cloudinary -> Gá»i Council.
    3. Náº¿u khÃ´ng -> Tráº£ vá» thÃ´ng bÃ¡o bÃ¬nh thÆ°á»ng (hoáº·c chat logic khÃ¡c).
    """
    
    # 1. Validate Conversation
    conversation = storage.get_conversation(conversation_id)
    if conversation is None:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # 2. Kiá»ƒm tra Keywords (Äiá»u kiá»‡n kÃ­ch hoáº¡t Task)
    trigger_keywords = ["scale", "expand", "extend", "outpainting", "má»Ÿ rá»™ng"]
    is_outpainting_task = any(keyword in content.lower() for keyword in trigger_keywords)

    image_url = None
    local_image_path = None
    image_data = None
    image_mime_type = "image/jpeg"

    # 3. Xá»­ lÃ½ áº£nh (Chá»‰ xá»­ lÃ½ náº¿u User cÃ³ gá»­i áº£nh)
    if image:
        # a. Äá»c bytes
        image_data = await image.read()
        
        # XÃ¡c Ä‘á»‹nh mime type
        filename = image.filename.lower() if image.filename else "image.jpg"
        if filename.endswith('.png'): image_mime_type = "image/png"
        elif filename.endswith('.webp'): image_mime_type = "image/webp"

        # b. LÆ¯U LOCAL
        # Táº¡o tÃªn file unique Ä‘á»ƒ trÃ¡nh trÃ¹ng Ä‘Ã¨
        local_filename = f"{uuid.uuid4()}_{filename}"
        local_image_path = os.path.join(LOCAL_IMG_DIR, local_filename)
        
        with open(local_image_path, "wb") as f:
            f.write(image_data)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u áº£nh local táº¡i: {local_image_path}")

        # c. UPLOAD CLOUDINARY (Äá»ƒ láº¥y URL public hiá»ƒn thá»‹ trÃªn Web Frontend)
        try:
            # Upload tá»« bytes data
            upload_result = cloudinary.uploader.upload(
                image_data, 
                folder="outpainting_tasks"
            )
            image_url = upload_result["secure_url"]
        except Exception as e:
            print(f"âš ï¸ Cloudinary upload failed: {e}")
            # Náº¿u lá»—i upload, ta váº«n cháº¡y tiáº¿p Ä‘Æ°á»£c vÃ¬ Ä‘Ã£ cÃ³ image_data vÃ  local path

    # 4. LÆ°u User Message vÃ o DB
    storage.add_user_message(conversation_id, content, image_url, local_image_path)
    
    # Cáº­p nháº­t title há»™i thoáº¡i
    if len(conversation["messages"]) == 0:
        short_title = (content[:30] + '...') if len(content) > 30 else content
        storage.update_conversation_title(conversation_id, short_title)

    # 5. QUYáº¾T Äá»ŠNH LOGIC Xá»¬ LÃ
    if is_outpainting_task and image_data:
        try:
            print(f"ğŸš€ Detected Outpainting Task for {conversation_id}...")
            
            # Gá»i Council (Truyá»n image_data trá»±c tiáº¿p Ä‘á»ƒ AI xá»­ lÃ½ nhanh nháº¥t)
            result = await council.run_task(
                user_query=content,
                image_url=image_url,       # Äá»ƒ AI reference náº¿u cáº§n
                image_data=image_data,     # Dá»¯ liá»‡u áº£nh raw (quan trá»ng cho Gemini REST)
                image_mime_type=image_mime_type
            )
            
            # LÆ°u káº¿t quáº£ AI
            storage.add_assistant_message(conversation_id, result, task_type="outpainting")
            return result

        except Exception as e:
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f"Council processing failed: {str(e)}")
            
    else:
        # TRÆ¯á»œNG Há»¢P: KhÃ´ng pháº£i task outpainting hoáº·c khÃ´ng cÃ³ áº£nh
        # Báº¡n cÃ³ thá»ƒ ná»‘i vÃ o má»™t Chatbot bÃ¬nh thÆ°á»ng á»Ÿ Ä‘Ã¢y.
        # Hiá»‡n táº¡i tÃ´i sáº½ tráº£ vá» má»™t thÃ´ng bÃ¡o Ä‘Æ¡n giáº£n.
        
        fallback_response = {
            "final_result": {
                "selected_response": "TÃ´i lÃ  AI chuyÃªn vá» Outpainting (Má»Ÿ rá»™ng tranh). Vui lÃ²ng gá»­i kÃ¨m má»™t bá»©c áº£nh vÃ  dÃ¹ng cÃ¡c tá»« khÃ³a nhÆ° 'expand', 'scale', 'outpainting' Ä‘á»ƒ tÃ´i báº¯t Ä‘áº§u lÃ m viá»‡c.",
                "selected_model": "system",
                "evaluation": "No task triggered"
            }
        }
        
        storage.add_assistant_message(conversation_id, fallback_response, task_type="chat")
        return fallback_response

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)